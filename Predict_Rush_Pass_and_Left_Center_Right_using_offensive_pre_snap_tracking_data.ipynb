{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/therocket290/cs228-material/blob/master/Predict_Rush_Pass_and_Left_Center_Right_using_offensive_pre_snap_tracking_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "50d3b3c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50d3b3c1",
        "outputId": "c40e7d72-c705-4517-981f-9b6353a22187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold, cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E39LH4R2Gi_",
        "outputId": "e7577f49-6a99-431d-c9ca-00474fddd7cd"
      },
      "id": "_E39LH4R2Gi_",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/NFL_Big_Data_Bowl/'"
      ],
      "metadata": {
        "id": "qmKYHSBM2KHP"
      },
      "id": "qmKYHSBM2KHP",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6307835a",
      "metadata": {
        "id": "6307835a"
      },
      "outputs": [],
      "source": [
        "games = pd.read_csv(path+'games.csv')\n",
        "player_play = pd.read_csv(path+'player_play.csv')\n",
        "players = pd.read_csv(path+'players.csv')\n",
        "plays = pd.read_csv(path+'plays.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "521200cc",
      "metadata": {
        "id": "521200cc"
      },
      "outputs": [],
      "source": [
        "player_position_dict = players.set_index('nflId')['position'].to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4ddad8db",
      "metadata": {
        "id": "4ddad8db"
      },
      "outputs": [],
      "source": [
        "def prep_training_data(df):\n",
        "    df['position'] = df.nflId.map(player_position_dict)\n",
        "    df = df[ df.playId.isin(list(df[ (df.event=='line_set') ].playId.unique())) ]\n",
        "    return(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2e202df",
      "metadata": {
        "id": "b2e202df"
      },
      "source": [
        "Add 'week' to the plays dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dcd3abff",
      "metadata": {
        "id": "dcd3abff"
      },
      "outputs": [],
      "source": [
        "plays = plays.merge(games[['gameId', 'week']], on='gameId', how='outer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4410062b",
      "metadata": {
        "id": "4410062b"
      },
      "outputs": [],
      "source": [
        "# A function to get tracking data for each week to make a dataframe\n",
        "def get_move_data(week, data):\n",
        "    week = week\n",
        "    df = data\n",
        "    position_list = []\n",
        "    game_list = []\n",
        "    play_list = []\n",
        "    overall_player_list = []\n",
        "    overall_xlist = []\n",
        "    overall_ylist = []\n",
        "    overall_dist_list = []\n",
        "    games_df = games[games.week==week]\n",
        "    plays_df = plays[plays['gameId'].isin(list(games_df.gameId.unique()))].reset_index()\n",
        "    play_count = 0\n",
        "    for i in range(plays_df.shape[0]):\n",
        "        if i%500==0:\n",
        "            print('Working on play ', i)\n",
        "        game = plays_df.loc[i,'gameId']\n",
        "        play = plays_df.loc[i,'playId']\n",
        "        offTeam = plays_df.loc[i, 'possessionTeam']\n",
        "        if (game in list(df.gameId.unique())) & (play in list(df.playId.unique())) & (len( df[(df.gameId==game) & (df.playId==play) & (df.event=='line_set') ]) > 0) & ( df[df.event=='line_set'].frameId.values[0] < df[(df.event=='ball_snap')|(df.event=='snap_direct')|(df.event=='autoevent_ballsnap')].frameId.values[0] + 1 ):\n",
        "            play_count = play_count+1\n",
        "            #print('found game')\n",
        "            df1 = df[(df.gameId==game) & (df.playId==play)]\n",
        "            offense = list(df1[df1.club==offTeam].nflId.unique())\n",
        "            line_set = df1[df1.event=='line_set'].frameId.values[0]\n",
        "            snap = df1[(df1.event=='ball_snap')|(df1.event=='snap_direct')|(df1.event=='autoevent_ballsnap')].frameId.values[0] + 1\n",
        "            df1 = df1[df1.frameId.isin(list(range(line_set,snap)))]\n",
        "            positions = []\n",
        "            player_list = []\n",
        "            dist_list = []\n",
        "            play_xlist = []\n",
        "            play_ylist = []\n",
        "            for player in offense:\n",
        "                player_list.append(player)\n",
        "                positions.append(players[players.nflId==player].position.values[0])\n",
        "                x_list = list(df1[(df1.nflId==player)].x.values.astype('float'))\n",
        "                y_list = list(df1[(df1.nflId==player)].y.values.astype('float'))\n",
        "                play_xlist.append(x_list)\n",
        "                play_ylist.append(y_list)\n",
        "                dist_list.append(df1[df1.nflId==player].dis.sum())\n",
        "            game_list.append(game)\n",
        "            play_list.append(play)\n",
        "            position_list.append(positions)\n",
        "            overall_player_list.append(player_list)\n",
        "            overall_xlist.append(play_xlist)\n",
        "            overall_ylist.append(play_ylist)\n",
        "            overall_dist_list.append(dist_list)\n",
        "        #print('List lengths:')\n",
        "        #print('play count:' + str(play_count))\n",
        "        #print(len(game_list))\n",
        "        #print(len(play_list))\n",
        "        #print(len(position_list))\n",
        "        #print(len(overall_player_list))\n",
        "        #print(len(overall_xlist))\n",
        "        #print(len(overall_ylist))\n",
        "        #print(len(overall_dist_list))\n",
        "    return(game_list, play_list, position_list, overall_player_list, overall_xlist, overall_ylist, overall_dist_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "926edc99",
      "metadata": {
        "id": "926edc99"
      },
      "outputs": [],
      "source": [
        "# A function to create a pandas dataframe using the lists produced by get_move_data()\n",
        "def make_move_df(game_list, play_list, position_list, overall_player_list, overall_xlist, overall_ylist, overall_dist_list):\n",
        "\n",
        "    move_df = pd.DataFrame(play_list, columns=['playId']).copy()\n",
        "    move_df['gameId'] = game_list\n",
        "    for i in range(move_df.shape[0]):\n",
        "        #print(i)\n",
        "        for p in range(11):\n",
        "            if len(overall_xlist[i][p]) > 0:\n",
        "                move_df.loc[i,'p'+str(p)+'_pos'] = position_list[i][p]\n",
        "                move_df.loc[i,'p'+str(p)+'_dist'] = overall_dist_list[i][p]\n",
        "                move_df.loc[i,'p'+str(p)+'_xstart'] = overall_xlist[i][p][0]\n",
        "                move_df.loc[i,'p'+str(p)+'_xend'] = overall_xlist[i][p][-1]\n",
        "                move_df.loc[i,'p'+str(p)+'_ystart'] = overall_ylist[i][p][0]\n",
        "                move_df.loc[i,'p'+str(p)+'_yend'] = overall_ylist[i][p][-1]\n",
        "                move_df.loc[i,'p'+str(p)+'_xmin'] = np.min(overall_xlist[i][p])\n",
        "                move_df.loc[i,'p'+str(p)+'_xmax'] = np.max(overall_xlist[i][p])\n",
        "                move_df.loc[i,'p'+str(p)+'_ymin'] = np.min(overall_ylist[i][p])\n",
        "                move_df.loc[i,'p'+str(p)+'_ymax'] = np.max(overall_ylist[i][p])\n",
        "            if len(overall_xlist[i][p]) == 0:\n",
        "                move_df.loc[i,'p'+str(p)+'_pos'] = np.nan\n",
        "                move_df.loc[i,'p'+str(p)+'_dist'] = np.nan\n",
        "                move_df.loc[i,'p'+str(p)+'_xstart'] = np.nan\n",
        "                move_df.loc[i,'p'+str(p)+'_xend'] = np.nan\n",
        "                move_df.loc[i,'p'+str(p)+'_ystart'] = np.nan\n",
        "                move_df.loc[i,'p'+str(p)+'_yend'] = np.nan\n",
        "                move_df.loc[i,'p'+str(p)+'_xmin'] = np.nan\n",
        "                move_df.loc[i,'p'+str(p)+'_xmax'] = np.nan\n",
        "                move_df.loc[i,'p'+str(p)+'_ymin'] = np.nan\n",
        "                move_df.loc[i,'p'+str(p)+'_ymax'] = np.nan\n",
        "\n",
        "    move_df = move_df.merge(plays[['playId', 'gameId', 'quarter', 'down', 'yardsToGo', 'possessionTeam',\n",
        "                     'defensiveTeam', 'yardlineSide', 'yardlineNumber', 'isDropback']], on=['playId','gameId'], how='left')\n",
        "    return move_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "058ab98d",
      "metadata": {
        "id": "058ab98d"
      },
      "outputs": [],
      "source": [
        "def add_pos_move(df, pos):\n",
        "    move_dfm = df\n",
        "    new_cols = 0\n",
        "    for i in range(move_dfm.shape[0]):\n",
        "        ind = np.where(move_dfm.iloc[i,:]==pos)\n",
        "        move_dfm.loc[i,pos+'_total_dist'] = move_dfm.iloc[i,ind[0]+1].sum()\n",
        "    for i in range(move_dfm.shape[0]):\n",
        "        ind = np.where(move_dfm.iloc[i,:]==pos)\n",
        "        #move_dfm.loc[i,'WR_total_dist'] =\n",
        "        #print('row ', i)\n",
        "        displacements = []\n",
        "        xdisplacements = []\n",
        "        indices = []\n",
        "        ymaxes = []\n",
        "        ymins = []\n",
        "        xmaxes = []\n",
        "        xmins = []\n",
        "        for k in ind[0]:\n",
        "            indices.append(k)\n",
        "            displacements.append(move_dfm.iloc[i,k+5] - move_dfm.iloc[i,k+4])\n",
        "            xdisplacements.append(move_dfm.iloc[i,k+3] - move_dfm.iloc[i,k+2])\n",
        "            ymins.append(move_dfm.iloc[i,k+8])\n",
        "            ymaxes.append(move_dfm.iloc[i,k+9])\n",
        "            xmins.append(move_dfm.iloc[i,k+6])\n",
        "            xmaxes.append(move_dfm.iloc[i,k+7])\n",
        "        temp_df = pd.DataFrame(displacements, columns=['disp'])\n",
        "        temp_df['ind'] = indices\n",
        "        temp_df['ymin'] = ymins\n",
        "        temp_df['ymax'] = ymaxes\n",
        "        temp_df['xdisp'] = xdisplacements\n",
        "        temp_df['xmin'] = xmins\n",
        "        temp_df['xmax'] = xmaxes\n",
        "        temp_df = temp_df.sort_values(by='disp', ascending=False).reset_index(drop=False)\n",
        "        move_dfm.loc[i,pos+'_total_ydisp'] = temp_df['disp'].sum()\n",
        "        new_cols = new_cols+1\n",
        "        move_dfm.loc[i,pos+'_overall_ymin'] = np.min(temp_df['ymin'])\n",
        "        new_cols = new_cols+1\n",
        "        move_dfm.loc[i,pos+'_overall_ymax'] = np.max(temp_df['ymax'])\n",
        "        new_cols = new_cols+1\n",
        "        move_dfm.loc[i,pos+'_total_xdisp'] = temp_df['xdisp'].sum()\n",
        "        new_cols = new_cols+1\n",
        "        move_dfm.loc[i,pos+'_overall_xmin'] = np.min(temp_df['xmin'])\n",
        "        new_cols = new_cols+1\n",
        "        move_dfm.loc[i,pos+'_overall_xmax'] = np.max(temp_df['xmax'])\n",
        "        new_cols = new_cols+1\n",
        "        for j in range(len(ind[0])):\n",
        "            move_dfm.loc[i,pos+'_'+str(j+1)+'_disp'] = temp_df.loc[j,'disp']\n",
        "            new_cols = new_cols+1\n",
        "            move_dfm.loc[i,pos+'_'+str(j+1)+'_ymin'] = temp_df.loc[j,'ymin']\n",
        "            new_cols = new_cols+1\n",
        "            move_dfm.loc[i,pos+'_'+str(j+1)+'_ymax'] = temp_df.loc[j,'ymax']\n",
        "            new_cols = new_cols+1\n",
        "            move_dfm.loc[i,pos+'_'+str(j+1)+'_xdisp'] = temp_df.loc[j,'xdisp']\n",
        "            new_cols = new_cols+1\n",
        "            move_dfm.loc[i,pos+'_'+str(j+1)+'_xmin'] = temp_df.loc[j,'xmin']\n",
        "            new_cols = new_cols+1\n",
        "            move_dfm.loc[i,pos+'_'+str(j+1)+'_xmax'] = temp_df.loc[j,'xmax']\n",
        "            new_cols = new_cols+1\n",
        "    move_dfm.iloc[:,-new_cols:] = move_dfm.iloc[:,-new_cols:].replace(to_replace={np.nan:-99})\n",
        "    return(move_dfm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19c5b6ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19c5b6ba",
        "outputId": "609e387e-65e7-4483-864b-9ef517ec8b16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on week 0...\n",
            "Working on play  0\n",
            "Working on play  500\n",
            "Working on play  1000\n",
            "Working on play  1500\n"
          ]
        }
      ],
      "source": [
        "move_dfs = []\n",
        "for w in range(9):\n",
        "    print('Working on week '+str(w)+'...')\n",
        "    df = pd.read_csv(path+'tracking_week_'+str(w+1)+'.csv')\n",
        "    data = get_move_data(w+1,df)\n",
        "    move_dfs.append(make_move_df(data[0], data[1], data[2], data[3], data[4], data[5], data[6]))\n",
        "move_df = pd.concat(move_dfs).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6232258c",
      "metadata": {
        "id": "6232258c"
      },
      "source": [
        "## Play location information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0575c2fd",
      "metadata": {
        "id": "0575c2fd"
      },
      "outputs": [],
      "source": [
        "pass_plays = plays[~plays.passLocationType.isna()]\n",
        "rush_plays = plays[~plays.rushLocationType.isna()]\n",
        "rush_plays['locationType'] = rush_plays['rushLocationType']\n",
        "rush_plays = rush_plays.drop(columns=['rushLocationType', 'passLocationType'])\n",
        "pass_plays['locationType'] = pass_plays['passLocationType']\n",
        "pass_plays = pass_plays.drop(columns=['passLocationType', 'rushLocationType'])\n",
        "marked_plays = pd.concat([rush_plays, pass_plays])\n",
        "marked_plays = marked_plays[marked_plays.locationType!='UNKNOWN'].reset_index(drop=True)\n",
        "marked_plays['locationType'] = marked_plays['locationType'].replace(to_replace={'INSIDE_RIGHT':'INSIDE',\n",
        "                                                                                'INSIDE_LEFT':'INSIDE',\n",
        "                                                                               'INSIDE_BOX':'INSIDE'})\n",
        "marked_plays['score_difference'] = marked_plays['preSnapHomeScore'] - marked_plays['preSnapVisitorScore']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9b3b70d",
      "metadata": {
        "id": "c9b3b70d"
      },
      "outputs": [],
      "source": [
        "marked_plays.locationType.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93d67768",
      "metadata": {
        "id": "93d67768"
      },
      "outputs": [],
      "source": [
        "move_df = move_df.merge(marked_plays[['gameId', 'playId', 'locationType',\n",
        "                                       'score_difference', 'preSnapHomeTeamWinProbability']], on=['gameId', 'playId'], how='outer').dropna(subset='p0_pos')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3154044a",
      "metadata": {
        "id": "3154044a"
      },
      "outputs": [],
      "source": [
        "for position in ['WR', 'TE', 'T', 'RB', 'FB', 'G']:\n",
        "    print('Working on ', position, '...')\n",
        "    move_df = add_pos_move(move_df, position)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "move_df.to_csv('move_df.csv', index=False)"
      ],
      "metadata": {
        "id": "MG05WAsz2vuu"
      },
      "id": "MG05WAsz2vuu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e341e28",
      "metadata": {
        "id": "6e341e28"
      },
      "outputs": [],
      "source": [
        "enc = LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdba77da",
      "metadata": {
        "id": "fdba77da"
      },
      "outputs": [],
      "source": [
        "move_df['yardlineSideOff'] = move_df['possessionTeam'] == move_df['yardlineSide']\n",
        "move_df['yardlineSideOff'] = move_df['yardlineSideOff'].astype('int')\n",
        "move_df = move_df.drop(columns=['yardlineSide'])\n",
        "move_df = pd.get_dummies(move_df, columns=['possessionTeam','defensiveTeam'])\n",
        "for col in list(move_df.columns):\n",
        "    if (move_df[col].dtype =='object')&(col!='possessionTeam')&(col!='defensiveTeam'):\n",
        "        move_df[col] = enc.fit_transform(move_df[col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f181d24",
      "metadata": {
        "id": "4f181d24"
      },
      "outputs": [],
      "source": [
        "X = move_dfm_dum.drop(columns=['playId', 'gameId', 'isDropback', 'locationType'])\n",
        "y = move_dfm_dum['isDropback'].astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57d999f2",
      "metadata": {
        "id": "57d999f2"
      },
      "outputs": [],
      "source": [
        "tree = lgb.LGBMClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d55716a0",
      "metadata": {
        "id": "d55716a0"
      },
      "outputs": [],
      "source": [
        "k = 5\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=290)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b89eb20",
      "metadata": {
        "id": "1b89eb20"
      },
      "outputs": [],
      "source": [
        "score_list = cross_val_score(tree, X, y, cv=kf, scoring='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "792e4337",
      "metadata": {
        "id": "792e4337"
      },
      "outputs": [],
      "source": [
        "average_acc = np.mean(score_list2)\n",
        "\n",
        "print(f\"Accuracy Score for each fold: {[round(score, 4) for score in score_list2]}\")\n",
        "print(f\"Average accuracy across {k} folds: {average_acc:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cc1b7e4",
      "metadata": {
        "id": "3cc1b7e4"
      },
      "outputs": [],
      "source": [
        "tree.fit(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ad296ff",
      "metadata": {
        "id": "5ad296ff"
      },
      "outputs": [],
      "source": [
        "lgb.plot_importance(tree, importance_type=\"gain\", figsize=(7,6), max_num_features=30,\n",
        "                    title=\"Feature importance for predicting rush vs pass (Gain)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "436b7d0d",
      "metadata": {
        "id": "436b7d0d"
      },
      "outputs": [],
      "source": [
        "lgb.plot_importance(tree, importance_type=\"split\", figsize=(7,6), max_num_features=30,\n",
        "                    title=\"Feature importance for predicting rush vs pass (Split)\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}